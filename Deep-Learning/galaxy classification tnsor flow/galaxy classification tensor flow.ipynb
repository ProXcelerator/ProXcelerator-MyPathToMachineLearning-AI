{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f7d5234-6819-456b-b963-71090727db82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#Loads data from url\n",
    "def make_request(url):\n",
    "    print(\"Requesting data from {}...\".format(url))\n",
    "    response = requests.get('https://content.codecademy.com/courses/deeplearning-with-tensorflow/'+url)\n",
    "    response.raise_for_status()\n",
    "    response_data = io.BytesIO(response.content)\n",
    "    return response_data\n",
    "    \n",
    "#Loads galaxy data\n",
    "def load_galaxy_data():\n",
    "  \n",
    "  #If cached file not found, loads data from url\n",
    "  if not os.path.isfile('./cached_data.npz'):\n",
    "     response_data = make_request(url='galaxydata.npz')\n",
    "\n",
    "     with open(\"cached_data.npz\",\"wb\") as save_file:\n",
    "      save_file.write(response_data.read())\n",
    " \n",
    "  #Load data using NumPy\n",
    "  data = np.load('cached_data.npz')\n",
    "\n",
    "  print(\"Successfully loaded galaxy data!\")\n",
    "  \n",
    "  return data[\"data\"],data[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac6f7f37-0075-4cfb-9735-1cdf27e2a31e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Visualizes convolutional layer activations\n",
    "def visualize_activations(model, validation_iterator):\n",
    "\n",
    "  #A keras model that will output our previous model's activations for each convolutional layer:\n",
    "  activation_extractor = tf.keras.Model(inputs=model.inputs, outputs=[layer.output for layer in model.layers if \"conv2d\" in layer.name])\n",
    "\n",
    "  #Take matplotlib frame and remove axes.\n",
    "  def clean_plot(plot):\n",
    "    plot.axes.get_xaxis().set_visible(False)\n",
    "    plot.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "  #Dict mapping from class numbers to string labels:\n",
    "  class_names = {0:\"Regular\",1:\"Ringed\",2:\"Merger\",3:\"Other\"}\n",
    "\n",
    "  #Loads a sample batch of data\n",
    "  sample_batch_input,sample_labels = validation_iterator.next()\n",
    " \n",
    "  #Grabs the first five images\n",
    "  sample_batch_input = sample_batch_input[:5]\n",
    "  sample_labels = sample_labels[:5]\n",
    "\n",
    "  #Makes predictions using model.predict(x)\n",
    "  sample_predictions = model.predict(sample_batch_input)\n",
    "\n",
    "  #Iterate of images, predictions, and true labels\n",
    "  for i,(image, prediction, label) in enumerate(zip(sample_batch_input, sample_predictions, sample_labels)):\n",
    "\n",
    "    image_name = \"Galaxy_{}\".format(i)\n",
    "\n",
    "    #Gets predicted class with highest probability\n",
    "\n",
    "    predicted_class = tf.argmax(prediction).numpy()\n",
    "\n",
    "    #Gets correct label\n",
    "    actual_class = tf.argmax(label).numpy()\n",
    "\n",
    "    print(image_name)\n",
    "    print(\"\\tModel prediction: {}\".format(prediction))\n",
    "    print(\"\\tTrue label: {} ({})\".format(class_names[actual_class], actual_class))\n",
    "    print(\"\\tCorrect:\", predicted_class == actual_class)\n",
    "\n",
    "    #Saves image file using matplotlib\n",
    "    sample_image = image\n",
    "    clean_plot(plt.imshow(sample_image))\n",
    "\n",
    "    plt.title(image_name+\" Predicted: {}, Actual: {}\".format(class_names[predicted_class], class_names[actual_class]))\n",
    "    plt.savefig('static/images/'+image_name+\".png\")\n",
    "    model_layer_output = activation_extractor(tf.expand_dims(sample_image,0))\n",
    "    \n",
    "    plt.clf()\n",
    "\n",
    "    #Iterates over each layer output\n",
    "    for l_num,output_data in enumerate(model_layer_output):\n",
    "\n",
    "      #Creates a subplot for each filter\n",
    "      fig, axs = plt.subplots(1, output_data.shape[-1])\n",
    "      \n",
    "      #For each filter\n",
    "      for i in range(output_data.shape[-1]):\n",
    "\n",
    "        #Plots the filter's activations\n",
    "        \n",
    "        clean_plot(axs[i].imshow(output_data[0][:, :, i], cmap=\"gray\"))\n",
    "      plt.suptitle(image_name+\" Conv {}\".format(l_num),y=0.6)\n",
    "      plt.savefig('static/images/' + image_name+ \"Conv{}.png\".format(l_num))\n",
    "      plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d3e9c16-9b6d-4001-888a-11f2f15fc730",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded galaxy data!\n",
      "(1400, 128, 128, 3) (1400, 4)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from utils import load_galaxy_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_data, labels = load_galaxy_data()\n",
    "\n",
    "print(input_data.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e646b21-6d5e-4f26-a106-8b4f04f473d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(input_data, labels, test_size=0.2, random_state=222, stratify=labels, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5394c27-234b-43fa-9051-a9a36c191fe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator = ImageDataGenerator(rescale=1.0/128)\n",
    "\n",
    "train_iterator = generator.flow(x_train, y_train, batch_size = 5)\n",
    "test_iterator = generator.flow(x_test, y_test, batch_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cec16e19-9239-4575-85c9-76b6deb4ccc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 63, 63, 8)         224       \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 31, 31, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 14, 14, 5)         645       \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 7, 7, 5)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 245)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                15744     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,873\n",
      "Trainable params: 16,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(128,128,3)))\n",
    "model.add(tf.keras.layers.Conv2D(8, 3, strides=2, activation='relu', padding='valid'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(tf.keras.layers.Conv2D(5, 4, strides=2, activation='relu', padding='valid'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adamax(learning_rate=.005), loss=[tf.keras.losses.CategoricalCrossentropy()], metrics=[tf.keras.metrics.CategoricalAccuracy(), tf.keras.metrics.AUC()])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ec0cd9f-bd9f-4d57-8991-c2f1c2a56333",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.1452 - categorical_accuracy: 0.9536 - auc_5: 0.9959 - val_loss: 1.1134 - val_categorical_accuracy: 0.7321 - val_auc_5: 0.8934\n",
      "Epoch 2/35\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.1329 - categorical_accuracy: 0.9536 - auc_5: 0.9970 - val_loss: 1.1313 - val_categorical_accuracy: 0.7357 - val_auc_5: 0.8904\n",
      "Epoch 3/35\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.1104 - categorical_accuracy: 0.9616 - auc_5: 0.9980 - val_loss: 1.2429 - val_categorical_accuracy: 0.7036 - val_auc_5: 0.8811\n",
      "Epoch 4/35\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.1009 - categorical_accuracy: 0.9714 - auc_5: 0.9982 - val_loss: 1.1745 - val_categorical_accuracy: 0.7143 - val_auc_5: 0.8936\n",
      "Epoch 5/35\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.0982 - categorical_accuracy: 0.9705 - auc_5: 0.9986 - val_loss: 1.1775 - val_categorical_accuracy: 0.7179 - val_auc_5: 0.8933\n",
      "Epoch 6/35\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.0902 - categorical_accuracy: 0.9688 - auc_5: 0.9988 - val_loss: 1.2094 - val_categorical_accuracy: 0.7393 - val_auc_5: 0.9012\n",
      "Epoch 7/35\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.0730 - categorical_accuracy: 0.9786 - auc_5: 0.9993 - val_loss: 1.2877 - val_categorical_accuracy: 0.7143 - val_auc_5: 0.8893\n",
      "Epoch 8/35\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.0609 - categorical_accuracy: 0.9812 - auc_5: 0.9996 - val_loss: 1.3111 - val_categorical_accuracy: 0.6964 - val_auc_5: 0.8950\n",
      "Epoch 9/35\n",
      "224/224 [==============================] - 1s 7ms/step - loss: 0.0546 - categorical_accuracy: 0.9875 - auc_5: 0.9995 - val_loss: 1.3768 - val_categorical_accuracy: 0.6857 - val_auc_5: 0.8872\n",
      "Epoch 10/35\n",
      "224/224 [==============================] - 1s 7ms/step - loss: 0.0565 - categorical_accuracy: 0.9884 - auc_5: 0.9995 - val_loss: 1.3718 - val_categorical_accuracy: 0.7250 - val_auc_5: 0.8921\n",
      "Epoch 11/35\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.0473 - categorical_accuracy: 0.9866 - auc_5: 0.9997 - val_loss: 1.3742 - val_categorical_accuracy: 0.6964 - val_auc_5: 0.8903\n",
      "Epoch 12/35\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.0401 - categorical_accuracy: 0.9884 - auc_5: 0.9997 - val_loss: 1.4250 - val_categorical_accuracy: 0.7071 - val_auc_5: 0.8885\n",
      "Epoch 13/35\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.0453 - categorical_accuracy: 0.9875 - auc_5: 0.9996 - val_loss: 1.3852 - val_categorical_accuracy: 0.7107 - val_auc_5: 0.8850\n",
      "Epoch 14/35\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.0399 - categorical_accuracy: 0.9893 - auc_5: 0.9998 - val_loss: 1.3726 - val_categorical_accuracy: 0.7071 - val_auc_5: 0.8851\n",
      "Epoch 15/35\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.0268 - categorical_accuracy: 0.9955 - auc_5: 0.9999 - val_loss: 1.4202 - val_categorical_accuracy: 0.7036 - val_auc_5: 0.8803\n",
      "Epoch 16/35\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.0274 - categorical_accuracy: 0.9973 - auc_5: 0.9999 - val_loss: 1.4505 - val_categorical_accuracy: 0.7036 - val_auc_5: 0.8808\n",
      "Epoch 17/35\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.0409 - categorical_accuracy: 0.9866 - auc_5: 0.9997 - val_loss: 1.4264 - val_categorical_accuracy: 0.6929 - val_auc_5: 0.8893\n",
      "Epoch 18/35\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.0182 - categorical_accuracy: 0.9955 - auc_5: 1.0000 - val_loss: 1.4165 - val_categorical_accuracy: 0.7107 - val_auc_5: 0.8878\n",
      "Epoch 19/35\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.0195 - categorical_accuracy: 0.9955 - auc_5: 1.0000 - val_loss: 1.4729 - val_categorical_accuracy: 0.7143 - val_auc_5: 0.8877\n",
      "Epoch 20/35\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.0108 - categorical_accuracy: 0.9982 - auc_5: 1.0000 - val_loss: 1.6180 - val_categorical_accuracy: 0.7000 - val_auc_5: 0.8766\n",
      "Epoch 21/35\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.0104 - categorical_accuracy: 0.9991 - auc_5: 1.0000 - val_loss: 1.6295 - val_categorical_accuracy: 0.7143 - val_auc_5: 0.8790\n",
      "Epoch 22/35\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.0390 - categorical_accuracy: 0.9866 - auc_5: 0.9997 - val_loss: 1.5219 - val_categorical_accuracy: 0.7107 - val_auc_5: 0.8861\n",
      "Epoch 23/35\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.0153 - categorical_accuracy: 0.9955 - auc_5: 1.0000 - val_loss: 1.6105 - val_categorical_accuracy: 0.7214 - val_auc_5: 0.8833\n",
      "Epoch 24/35\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.0049 - categorical_accuracy: 1.0000 - auc_5: 1.0000 - val_loss: 1.6372 - val_categorical_accuracy: 0.7071 - val_auc_5: 0.8791\n",
      "Epoch 25/35\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.0045 - categorical_accuracy: 1.0000 - auc_5: 1.0000 - val_loss: 1.5920 - val_categorical_accuracy: 0.7214 - val_auc_5: 0.8867\n",
      "Epoch 26/35\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.0104 - categorical_accuracy: 0.9982 - auc_5: 1.0000 - val_loss: 1.6300 - val_categorical_accuracy: 0.7143 - val_auc_5: 0.8854\n",
      "Epoch 27/35\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.0032 - categorical_accuracy: 1.0000 - auc_5: 1.0000 - val_loss: 1.6327 - val_categorical_accuracy: 0.7214 - val_auc_5: 0.8891\n",
      "Epoch 28/35\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.0025 - categorical_accuracy: 1.0000 - auc_5: 1.0000 - val_loss: 1.7346 - val_categorical_accuracy: 0.7143 - val_auc_5: 0.8853\n",
      "Epoch 29/35\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.0028 - categorical_accuracy: 1.0000 - auc_5: 1.0000 - val_loss: 1.7054 - val_categorical_accuracy: 0.7286 - val_auc_5: 0.8851\n",
      "Epoch 30/35\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.0519 - categorical_accuracy: 0.9804 - auc_5: 0.9995 - val_loss: 1.6813 - val_categorical_accuracy: 0.7214 - val_auc_5: 0.8725\n",
      "Epoch 31/35\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.0043 - categorical_accuracy: 1.0000 - auc_5: 1.0000 - val_loss: 1.7232 - val_categorical_accuracy: 0.7286 - val_auc_5: 0.8823\n",
      "Epoch 32/35\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.0032 - categorical_accuracy: 1.0000 - auc_5: 1.0000 - val_loss: 1.7289 - val_categorical_accuracy: 0.7143 - val_auc_5: 0.8770\n",
      "Epoch 33/35\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.0018 - categorical_accuracy: 1.0000 - auc_5: 1.0000 - val_loss: 1.7386 - val_categorical_accuracy: 0.7286 - val_auc_5: 0.8786\n",
      "Epoch 34/35\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - auc_5: 1.0000 - val_loss: 1.7620 - val_categorical_accuracy: 0.7321 - val_auc_5: 0.8809\n",
      "Epoch 35/35\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.0014 - categorical_accuracy: 1.0000 - auc_5: 1.0000 - val_loss: 1.7792 - val_categorical_accuracy: 0.7107 - val_auc_5: 0.8793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x238af3c7cd0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 5\n",
    "model.fit(train_iterator, steps_per_epoch=len(x_train)/batch_size, epochs=35, validation_data=test_iterator, validation_steps=len(x_test)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2c85631-9514-4f8b-83d9-9b0ae91a32b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Galaxy_0\n",
      "\tModel prediction: [6.1706245e-01 3.7997067e-01 2.9298768e-03 3.6989913e-05]\n",
      "\tTrue label: Regular (0)\n",
      "\tCorrect: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Galaxy_1\n",
      "\tModel prediction: [5.4908207e-09 9.9999928e-01 2.9993763e-09 7.6622518e-07]\n",
      "\tTrue label: Ringed (1)\n",
      "\tCorrect: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Galaxy_2\n",
      "\tModel prediction: [0.11014552 0.87521744 0.00166742 0.01296962]\n",
      "\tTrue label: Ringed (1)\n",
      "\tCorrect: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Galaxy_3\n",
      "\tModel prediction: [4.7871640e-09 1.0000000e+00 4.8509041e-10 4.9612984e-11]\n",
      "\tTrue label: Ringed (1)\n",
      "\tCorrect: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Galaxy_4\n",
      "\tModel prediction: [8.4353536e-03 9.9156451e-01 2.6744676e-08 6.0241327e-08]\n",
      "\tTrue label: Ringed (1)\n",
      "\tCorrect: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_activations(model, test_iterator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
