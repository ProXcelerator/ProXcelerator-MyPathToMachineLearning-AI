{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8c0de92-da7c-42d9-a1f0-582571149737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1698b8a-5ce6-43e8-9257-b99fcd8c48e3",
   "metadata": {},
   "source": [
    "This Model contains variables that are related to car evaluation.  \n",
    "Things that would be related to buying a car and wether the car is accptable to buy or not.  \n",
    "\n",
    "I will see if I can use a Decision Tree Classifier to produce a reasonable result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951f0355-36b4-4e1c-98a0-a0e76dd0414a",
   "metadata": {},
   "source": [
    "# Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad85c6b0-a18b-432c-a7db-548fdc237533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     buying  maint  doors persons lug_boot safety  accep\n",
      "0     vhigh  vhigh      2       2    small    low  unacc\n",
      "1     vhigh  vhigh      2       2    small    med  unacc\n",
      "2     vhigh  vhigh      2       2    small   high  unacc\n",
      "3     vhigh  vhigh      2       2      med    low  unacc\n",
      "4     vhigh  vhigh      2       2      med    med  unacc\n",
      "...     ...    ...    ...     ...      ...    ...    ...\n",
      "1723    low    low  5more    more      med    med   good\n",
      "1724    low    low  5more    more      med   high  vgood\n",
      "1725    low    low  5more    more      big    low  unacc\n",
      "1726    low    low  5more    more      big    med   good\n",
      "1727    low    low  5more    more      big   high  vgood\n",
      "\n",
      "[1728 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset to a pandas DataFrame\n",
    "path_to_data = 'https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data'\n",
    "column_names = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'accep']\n",
    "df = pd.read_csv(path_to_data, names=column_names)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b699cea1-69fe-4f2e-850e-a76dc2434e1f",
   "metadata": {},
   "source": [
    "# Features and Labels\n",
    "\n",
    "One hot encode the features and set the labels to binary values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5634a335-cb09-4b74-87ff-5b62dd0649f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'accep'\n",
    "raw_feature_columns = [col for col in column_names if col != target_column]\n",
    "\n",
    "# Create dummy variables from the feature columns\n",
    "X = pd.get_dummies(df[raw_feature_columns], drop_first=True)\n",
    "\n",
    "# Convert target column to binary variable; 0 if 'unacc', 1 otherwise\n",
    "df[target_column] = np.where(df[target_column] == 'unacc', 0, 1)\n",
    "y = df[target_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6675ad-bac8-41fe-b5bd-639e3edc2c15",
   "metadata": {},
   "source": [
    "# Split The Data\n",
    "Train Test Split gives us something to test after we train our training set.  \n",
    "This will give us something to test out predictions so we don't test on trained data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "622658fd-e0bf-4ded-b09c-115916f86fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the full dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eb5cd3-cb4d-4657-9049-5f6dbb1d05b6",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fa907ba-91f4-4f96-9c6e-838d078906ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "# 1. Create a decision stump base model using the Decision Tree Classifier and print its parameters\n",
    "# a decision stump uses a depth of 1 and only makes 2 leaf nodes\n",
    "decision_stump = DecisionTreeClassifier(max_depth=1)\n",
    "decision_stump.fit(X_train, y_train)\n",
    "y_pred = decision_stump.predict(X_test)\n",
    "print(decision_stump.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b711c3d-b111-4d31-ab6f-0fe0987aa843",
   "metadata": {},
   "source": [
    "# Boost the Decision Tree\n",
    "\n",
    "The Adaboostclassifier will give us better parameters that will produce a better score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dc22878-1fdf-4fb0-8dee-d0c7bd494224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'SAMME.R', 'base_estimator': 'deprecated', 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': 1, 'estimator__max_features': None, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__random_state': None, 'estimator__splitter': 'best', 'estimator': DecisionTreeClassifier(max_depth=1), 'learning_rate': 1.0, 'n_estimators': 5, 'random_state': None}\n"
     ]
    }
   ],
   "source": [
    "# 2. Create an Adaptive Boost Classifier and print its parameters\n",
    "ada_classifier = AdaBoostClassifier(estimator=decision_stump, n_estimators=5)\n",
    "print(ada_classifier.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd9acb2-2d18-4f60-9745-ad9105dba339",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2675813-c58c-4aed-baf0-bd351fed477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Fit the Adaptive Boost Classifier to the training data and get the list of predictions\n",
    "ada_classifier.fit(X_train, y_train)\n",
    "y_pred = ada_classifier.predict(X_test)\n",
    "\n",
    "# 4. Calculate the accuracy, precision, recall, and f1-score on the testing data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf9034f-8f92-4771-bc8b-13530adf0887",
   "metadata": {},
   "source": [
    "# Prediction Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb01de34-090d-467c-b69d-ac065d155022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "            predicted yes  predicted no\n",
      "actual yes            129            25\n",
      "actual no              49           316\n",
      "Accuracy score : 0.8574181117533719\n",
      "Precision score : 0.7247191011235955\n",
      "Recall score : 0.8376623376623377\n",
      "f1 score : 0.7771084337349398\n"
     ]
    }
   ],
   "source": [
    "# 5. Remove the comments from the following code block to print the confusion matrix\n",
    "test_conf_matrix = pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred, labels=[1, 0]), \n",
    "    index=['actual yes', 'actual no'], \n",
    "    columns=['predicted yes', 'predicted no']\n",
    ")\n",
    "print(f'Confusion Matrix:\\n{test_conf_matrix.to_string()}')\n",
    "\n",
    "print(f'Accuracy score : {accuracy}')\n",
    "print(f'Precision score : {precision}')\n",
    "print(f'Recall score : {recall}')\n",
    "print(f'f1 score : {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f7d165-5208-4e8a-bac6-72bd7b510fa0",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a11f25-63f9-41b9-b54d-8417a283a1d4",
   "metadata": {},
   "source": [
    "The accuracy is at 85% which isnt too bad for a simple model like this.  \n",
    "looking at the f1 score will give a better representation on how the model is performing.  \n",
    "With a f1 score of .77 its not performing good enough to be super useful.  \n",
    "We could use other models like Randomized Decision Tree, or SVM to see if they might perform better. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
