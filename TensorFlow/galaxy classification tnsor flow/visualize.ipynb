{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e285a024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Visualizes convolutional layer activations\n",
    "def visualize_activations(model, validation_iterator):\n",
    "\n",
    "  #A keras model that will output our previous model's activations for each convolutional layer:\n",
    "  activation_extractor = tf.keras.Model(inputs=model.inputs, outputs=[layer.output for layer in model.layers if \"conv2d\" in layer.name])\n",
    "\n",
    "  #Take matplotlib frame and remove axes.\n",
    "  def clean_plot(plot):\n",
    "    plot.axes.get_xaxis().set_visible(False)\n",
    "    plot.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "  #Dict mapping from class numbers to string labels:\n",
    "  class_names = {0:\"Regular\",1:\"Ringed\",2:\"Merger\",3:\"Other\"}\n",
    "\n",
    "  #Loads a sample batch of data\n",
    "  sample_batch_input,sample_labels = validation_iterator.next()\n",
    " \n",
    "  #Grabs the first five images\n",
    "  sample_batch_input = sample_batch_input[:5]\n",
    "  sample_labels = sample_labels[:5]\n",
    "\n",
    "  #Makes predictions using model.predict(x)\n",
    "  sample_predictions = model.predict(sample_batch_input)\n",
    "\n",
    "  #Iterate of images, predictions, and true labels\n",
    "  for i,(image, prediction, label) in enumerate(zip(sample_batch_input, sample_predictions, sample_labels)):\n",
    "\n",
    "    image_name = \"Galaxy_{}\".format(i)\n",
    "\n",
    "    #Gets predicted class with highest probability\n",
    "\n",
    "    predicted_class = tf.argmax(prediction).numpy()\n",
    "\n",
    "    #Gets correct label\n",
    "    actual_class = tf.argmax(label).numpy()\n",
    "\n",
    "    print(image_name)\n",
    "    print(\"\\tModel prediction: {}\".format(prediction))\n",
    "    print(\"\\tTrue label: {} ({})\".format(class_names[actual_class], actual_class))\n",
    "    print(\"\\tCorrect:\", predicted_class == actual_class)\n",
    "\n",
    "    #Saves image file using matplotlib\n",
    "    sample_image = image\n",
    "    clean_plot(plt.imshow(sample_image))\n",
    "\n",
    "    plt.title(image_name+\" Predicted: {}, Actual: {}\".format(class_names[predicted_class], class_names[actual_class]))\n",
    "    plt.savefig('static/images/'+image_name+\".png\")\n",
    "    model_layer_output = activation_extractor(tf.expand_dims(sample_image,0))\n",
    "    \n",
    "    plt.clf()\n",
    "\n",
    "    #Iterates over each layer output\n",
    "    for l_num,output_data in enumerate(model_layer_output):\n",
    "\n",
    "      #Creates a subplot for each filter\n",
    "      fig, axs = plt.subplots(1, output_data.shape[-1])\n",
    "      \n",
    "      #For each filter\n",
    "      for i in range(output_data.shape[-1]):\n",
    "\n",
    "        #Plots the filter's activations\n",
    "        \n",
    "        clean_plot(axs[i].imshow(output_data[0][:, :, i], cmap=\"gray\"))\n",
    "      plt.suptitle(image_name+\" Conv {}\".format(l_num),y=0.6)\n",
    "      plt.savefig('static/images/' + image_name+ \"Conv{}.png\".format(l_num))\n",
    "      plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
